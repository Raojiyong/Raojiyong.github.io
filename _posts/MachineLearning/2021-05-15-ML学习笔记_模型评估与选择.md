---
title: ML-模型评估与选择
author: raojiyong
date: 2021-05-15 15:00:00 +0800
categories ["2021","05"]
tags: notes
---

## 模型评估与选择

### 经验误差与过拟合

**训练误差/经验误差**学习器在训练集上的误差。

**泛化误差**学习器在新样本上的误差。

希望得到泛化误差最小的学习器，实际上能做的事努力使经验误差最小。



**过拟合**已经把训练样本自身的一些特点当作所有潜在样本都具有的一般性质。这样会导致泛化性能下降。

**欠拟合**训练样本的一般性质未学习好。

导致过拟合的原因：

- 学习能力过于强大，过度训练
- 数据量太小
- 数据质量很差，有很多噪声，模型学习到噪声规律

常见过拟合解决方案：

1. 模型层面 （减少模型的复杂度）

   - 正则化。包含L1和L2范数，一般使用L1番薯，使得模型拟合的参数大部分为0，从降低参数值和参数个数的角度**减少模型的复杂度**。
   - 权值共享。常用于深度学习，在网络中，不同层使用相同参数，减少参数。
   - dropout。丢弃学习，**关键是保留核心特征**，对于神经网络单元，按照一定概率暂时从网络中丢弃，分为两个阶段：学习阶段和测试阶段。
   - batch normalization。批标准化处理，作用非常大。可看作一个BN层，在一层层添加神经网络时，先有数据，再添加全连接层，全连接层的计算结果会经过 激励函数 成为下一层的输入。batch normalization就被添加到每一个全连接层和激励函数之间。其作用是：使得每一层的数据分布不变，做做标准化处理，加快模型收敛速度、避免梯度消失、提高准确率。
   - 权值衰减。weight_decay，简单理解就是乘在正则前面的系数

   ``optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9,weight_decay=1e-5)``

2. 数据层面 
   - 保证数据分布一致性。
   - 增加数据集的规模。

### 评估方法

测试集尽量与训练集互斥。划分数据集有以下方法：

#### 留出法

直接将数据集D划分成两个互斥的集合。划分尽可能保证数据分布的一致性。

**分层采样**是保留类别比例的采样方式。

单次使用留出法得到的估计结果不够稳定可靠，一般要使用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。

常见的做法是将大约2/3~4/5的样本作为训练，剩余的作为测试。

#### 交叉验证法 

 将D划分成k个大小相似的互斥子集，即$D=D_1\cup D_2\cup D_3\cup ...\cup D_k,D_i\cap D_j=\varnothing(i\neq j)$。每个子集都尽可能保持数据分布的一致性，即从D中通过分层采样得到。



